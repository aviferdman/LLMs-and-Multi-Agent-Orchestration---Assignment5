# Context Windows Research - Environment Configuration
# Copy this file to .env and fill in your values

# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2:13b

# OpenAI Configuration (Optional - for comparison)
# OPENAI_API_KEY=your_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo

# Experiment Configuration
RANDOM_SEED=42
NUM_RUNS=3
OUTPUT_DIR=results/

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/experiment.log

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=data/chroma_db

# Performance Settings
MAX_WORKERS=4
TIMEOUT_SECONDS=120

# Testing
TEST_MODE=false
MOCK_LLM_RESPONSES=false
